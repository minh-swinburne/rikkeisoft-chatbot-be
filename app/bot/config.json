{
  "timeout": {
    "total": 10,
    "read": 3,
    "write": 5,
    "connect": 2
  },
  "answer_generation": {
    "params": {
      "model": "llama-3.3-70b-versatile",
      "max_tokens": 4096,
      "temperature": 0.4,
      "top_p": 1,
      "stop": null,
      "stream": true
    },
    "model_options": [
      "llama-3.3-70b-versatile",
      "llama3-70b-8192",
      "llama-3.1-8b-instant",
      "llama-3.2-90b-vision-preview",
      "gemma2-9b-it"
    ],
    "system_prompt": "Instructions:\n- Be helpful and answer questions concisely. If you don't know the answer or can't find the relevant documents, let the user know.\n- Utilize the context provided for accurate and specific information.\n- Incorporate your pre-existing knowledge to enhance the depth and relevance of your response.\n- Cite your sources, including the title of relevant documents, as a list at the end of your answer.\n\nContext:\n{context}\n\nSources:\n{sources}"
  },
  "question_suggestion": {
    "params": {
      "model": "llama-3.2-1b-preview",
      "max_tokens": 128,
      "temperature": 0.5,
      "top_p": 1,
      "stop": null,
      "stream": false
    },
    "system_prompt": "Instructions:\n- Suggest 3 to 4 helpful and contextually relevant questions that the user may ask next.\n- Base your suggestions on the user's chat history and provided context.\n- Keep the questions concise and relevant to the conversation.\n- Return suggested questions as a simple ordered list of the questions themselves only, without any additional information, justification or formatting.\n\nFormat: \n1. Question 1?\n2. Question 2?\n3. Question 3?\n\nChat History: {chat_history}\n{context}\nExamples: {message_template}",
    "message_template": [
      "What is the summary of the document?",
      "Who created this document?",
      "What are the main points?",
      "When was this document uploaded?",
      "Can you provide a detailed explanation?",
      "Who?"
    ],
    "model_options": [
      "llama-3.2-1b-preview",
      "llama-3.2-3b-preview",
      "mixtral-8x7b-32768"
    ]
  },
  "name_generation": {
    "params": {
      "model": "llama-3.2-1b-preview",
      "max_tokens": 8,
      "temperature": 0.5,
      "top_p": 1,
      "stop": null,
      "stream": false
    },
    "model_options": [
      "llama-3.2-1b-preview",
      "llama-3.2-3b-preview",
      "mixtral-8x7b-32768"
    ],
    "system_prompt": "Instructions:\n- Generate a name for the chat based on the provided chat history.\n- The name should be concise, descriptive and relevant to the conversation.\n- Return ONLY the name as a single sentence or phrase, in plaintext. Nothing else should be included.\n\nChat History: {chat_history}"
  }
}