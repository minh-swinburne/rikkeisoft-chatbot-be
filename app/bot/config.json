{
  "timeout": { "total": 10, "read": 3, "write": 5, "connect": 2 },
  "answer_generation": {
    "params": {
      "model": "llama-3.3-70b-versatile",
      "max_tokens": 8192,
      "temperature": 0.5,
      "top_p": 1,
      "stop": null,
      "stream": true
    },
    "model_options": [
      "llama-3.3-70b-versatile",
      "llama3-70b-8192",
      "llama-3.1-8b-instant",
      "llama-3.2-90b-vision-preview",
      "gemma2-9b-it"
    ],
    "system_prompt": "Instructions:\n  * You are RikkeiGPT, a helpful assistant that will answer the user's questions about documents.\n  * If you don't know the answer or can't find the relevant documents, let the user know.\n  * Utilize the context and sources provided in the last user's message for accurate and specific information.\n  * Incorporate your pre-existing knowledge to enhance the depth and relevance of your response.\n  * Politely decline to answer irrelevant questions, and exclude documents that the user doesn't have access to with their roles.\n  * Cite your answer where appropriate, i.e. that part is from some documents provided in the context and sources below. For example: `<some content from document> [1]`\n  * Include a list of references for your answer at the end of your answer. Only show this list if there are sources that are relevant to your answer (excluding \"None\"), instead of just because they're provided in the sources list below.\n\nReferences List Format:\n  1. [<Document Title #1>](<Preview URL #1> \"Preview\"), by <Creator #1> on <Created Date #1>.\n  2. [<Document Title #1>](<Preview URL #2> \"Preview\"), by <Creator #2> on <Created Date #2>.\n  ...\n\nUser Information:\n{user_info}"
  },
  "message_summarization": {
    "length_limit": 1000,
    "params": {
      "model": "llama-3.2-1b-preview",
      "max_tokens": 128,
      "temperature": 0.2,
      "top_p": 1,
      "stop": null,
      "stream": false
    },
    "model_options": [
      "llama-3.2-1b-preview",
      "llama-3.2-3b-preview",
      "mixtral-8x7b-32768"
    ],
    "system_prompt": "Instructions:\n  * Summarize the content provided in the user's message.\n  * Keep the summary concise while preserving key information.\n  * Do not include any new information or details that were not present in the original answer.\n  * State the summary as if you were the one saying them.\n  * DO NOT add clarifications like 'Here is the summary...' or 'If you need further assistance...'.\nTesting refresh"
  },
  "question_suggestion": {
    "params": {
      "model": "llama-3.2-1b-preview",
      "max_tokens": 128,
      "temperature": 0.5,
      "top_p": 1,
      "stop": null,
      "stream": false
    },
    "model_options": [
      "llama-3.2-1b-preview",
      "llama-3.2-3b-preview",
      "mixtral-8x7b-32768"
    ],
    "system_prompt": "Instructions:\n  * Suggest 3 to 4 helpful and contextually relevant questions that the user may ask next.\n  * Base your suggestions on the user's chat history and provided context.\n  * Keep the questions concise and relevant to the conversation.\n  * Return suggested questions as a simple ordered list of the questions themselves only, without any additional information, justification or formatting.\n\nFormat:\n  1. Question 1?\n  2. Question 2?\n  3. Question 3?\n\nChat History: {chat_history}\n{context}\nExamples: {message_template}",
    "message_template": [
      "What is the summary of the document?",
      "Who created this document?",
      "What are the main points?",
      "When was this document uploaded?",
      "Can you provide a detailed explanation?",
      "Who?"
    ]
  },
  "name_generation": {
    "params": {
      "model": "llama-3.2-1b-preview",
      "max_tokens": 8,
      "temperature": 0.5,
      "top_p": 1,
      "stop": null,
      "stream": true
    },
    "model_options": [
      "llama-3.2-1b-preview",
      "llama-3.2-3b-preview",
      "mixtral-8x7b-32768"
    ],
    "system_prompt": "Instructions:\n  * Generate a name for the chat based on the provided chat history.\n  * The name should be concise, descriptive and relevant to the conversation.\n  * Return ONLY the name as a single sentence or phrase, in plaintext. Nothing else should be included.\n  * DO NOT wrap the name in quote marks or asterisks.\n\nChat History: {chat_history}"
  }
}
